{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# Multi-Layer Perceptron from Scratch\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "7192f319",
                              "metadata": {},
                              "source": [
                                        "This notebook builds a fully connected neural network using only NumPy and the Python standard library.\n",
                                        "\n",
                                        "**Notebook outline**\n",
                                        "\n",
                                        "- Load a mock multi-class classification dataset.\\n\n",
                                        "- Implement reusable activation functions and training utilities.\n",
                                        "- Build an `MLP` class that supports forward pass, backpropagation, and gradient updates.\n",
                                        "- Train the network with mini-batch gradient descent and evaluate its performance.\n",
                                        "- Visualise decision boundaries and learning curves.\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "from __future__ import annotations\n",
                                        "\n",
                                        "import math\n",
                                        "from pathlib import Path\n",
                                        "from typing import Iterable, Tuple\n",
                                        "\n",
                                        "import matplotlib.pyplot as plt\n",
                                        "import numpy as np\n",
                                        "\n",
                                        "np.random.seed(42)\n",
                                        "np.set_printoptions(precision=4, suppress=True)\n",
                                        "plt.style.use(\"ggplot\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "DATASET_PATH = Path(\"../data/mock_classification.csv\")\n",
                                        "\n",
                                        "if not DATASET_PATH.exists():\n",
                                        "    raise FileNotFoundError(\n",
                                        "        f\"Expected dataset at {DATASET_PATH}. Run the data preparation script first.\"\n",
                                        "    )\n",
                                        "\n",
                                        "data = np.loadtxt(DATASET_PATH, delimiter=\",\", skiprows=1)\n",
                                        "\n",
                                        "X = data[:, :2]\n",
                                        "y = data[:, 2].astype(int)\n",
                                        "\n",
                                        "num_samples, num_features = X.shape\n",
                                        "num_classes = int(y.max() + 1)\n",
                                        "\n",
                                        "print(f\"Loaded {num_samples} samples with {num_features} features and {num_classes} classes.\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def train_test_split(\n",
                                        "    X: np.ndarray,\n",
                                        "    y: np.ndarray,\n",
                                        "    test_ratio: float = 0.2,\n",
                                        "    seed: int = 0,\n",
                                        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
                                        "    rng = np.random.default_rng(seed)\n",
                                        "    indices = np.arange(X.shape[0])\n",
                                        "    rng.shuffle(indices)\n",
                                        "\n",
                                        "    test_size = int(np.floor(test_ratio * len(indices)))\n",
                                        "    test_indices = indices[:test_size]\n",
                                        "    train_indices = indices[test_size:]\n",
                                        "\n",
                                        "    return (\n",
                                        "        X[train_indices],\n",
                                        "        X[test_indices],\n",
                                        "        y[train_indices],\n",
                                        "        y[test_indices],\n",
                                        "    )\n",
                                        "\n",
                                        "\n",
                                        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_ratio=0.2, seed=123)\n",
                                        "\n",
                                        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
                                        "print(f\"Test set:  {X_test.shape[0]} samples\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def plot_data(X: np.ndarray, y: np.ndarray, title: str) -> None:\n",
                                        "    plt.figure(figsize=(6, 5))\n",
                                        "    for cls in np.unique(y):\n",
                                        "        plt.scatter(\n",
                                        "            X[y == cls, 0],\n",
                                        "            X[y == cls, 1],\n",
                                        "            label=f\"class {cls}\",\n",
                                        "            alpha=0.75,\n",
                                        "            edgecolor=\"k\",\n",
                                        "            s=40,\n",
                                        "        )\n",
                                        "    plt.xlabel(\"feature 1\")\n",
                                        "    plt.ylabel(\"feature 2\")\n",
                                        "    plt.title(title)\n",
                                        "    plt.legend()\n",
                                        "    plt.show()\n",
                                        "\n",
                                        "\n",
                                        "plot_data(X_train, y_train, \"Training Data Distribution\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def one_hot(indices: np.ndarray, depth: int) -> np.ndarray:\n",
                                        "    encoded = np.zeros((indices.size, depth), dtype=np.float64)\n",
                                        "    encoded[np.arange(indices.size), indices] = 1.0\n",
                                        "    return encoded\n",
                                        "\n",
                                        "\n",
                                        "def relu(z: np.ndarray) -> np.ndarray:\n",
                                        "    return np.maximum(0.0, z)\n",
                                        "\n",
                                        "\n",
                                        "def relu_derivative(z: np.ndarray) -> np.ndarray:\n",
                                        "    return (z > 0).astype(np.float64)\n",
                                        "\n",
                                        "\n",
                                        "def softmax(logits: np.ndarray) -> np.ndarray:\n",
                                        "    shifted = logits - np.max(logits, axis=1, keepdims=True)\n",
                                        "    exp_values = np.exp(shifted)\n",
                                        "    return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
                                        "\n",
                                        "\n",
                                        "def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
                                        "    return float(np.mean(y_true == y_pred))\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "class MLP:\n",
                                        "    def __init__(self, layer_sizes: Iterable[int], learning_rate: float = 0.05, l2: float = 0.0) -> None:\n",
                                        "        sizes = tuple(layer_sizes)\n",
                                        "        if len(sizes) < 2:\n",
                                        "            raise ValueError(\"layer_sizes must include at least an input and an output dimension.\")\n",
                                        "        self.layer_sizes = sizes\n",
                                        "        self.learning_rate = learning_rate\n",
                                        "        self.l2 = l2\n",
                                        "\n",
                                        "        self.weights: list[np.ndarray] = []\n",
                                        "        self.biases: list[np.ndarray] = []\n",
                                        "\n",
                                        "        rng = np.random.default_rng(42)\n",
                                        "        for idx in range(len(sizes) - 1):\n",
                                        "            in_features = sizes[idx]\n",
                                        "            out_features = sizes[idx + 1]\n",
                                        "            if idx == len(sizes) - 2:\n",
                                        "                scale = np.sqrt(1.0 / in_features)\n",
                                        "            else:\n",
                                        "                scale = np.sqrt(2.0 / in_features)\n",
                                        "            weight_matrix = rng.normal(loc=0.0, scale=scale, size=(in_features, out_features))\n",
                                        "            bias_vector = np.zeros((1, out_features), dtype=np.float64)\n",
                                        "            self.weights.append(weight_matrix)\n",
                                        "            self.biases.append(bias_vector)\n",
                                        "\n",
                                        "        self._cache: dict[str, list[np.ndarray]] = {}\n",
                                        "        self._grads: dict[str, list[np.ndarray]] = {}\n",
                                        "\n",
                                        "    def forward(self, X: np.ndarray, store: bool = True) -> np.ndarray:\n",
                                        "        activations = [X]\n",
                                        "        pre_activations = []\n",
                                        "        current = X\n",
                                        "\n",
                                        "        for idx, (weights, bias) in enumerate(zip(self.weights, self.biases)):\n",
                                        "            z = current @ weights + bias\n",
                                        "            pre_activations.append(z)\n",
                                        "            if idx == len(self.weights) - 1:\n",
                                        "                current = softmax(z)\n",
                                        "            else:\n",
                                        "                current = relu(z)\n",
                                        "            activations.append(current)\n",
                                        "\n",
                                        "        if store:\n",
                                        "            self._cache = {\n",
                                        "                \"activations\": activations,\n",
                                        "                \"pre_activations\": pre_activations,\n",
                                        "            }\n",
                                        "\n",
                                        "        return current\n",
                                        "\n",
                                        "    def compute_loss(self, y_one_hot: np.ndarray, probabilities: np.ndarray) -> float:\n",
                                        "        eps = 1e-12\n",
                                        "        batch_size = y_one_hot.shape[0]\n",
                                        "        ce = -np.sum(y_one_hot * np.log(probabilities + eps)) / batch_size\n",
                                        "        if self.l2:\n",
                                        "            ce += 0.5 * self.l2 * sum(np.sum(w * w) for w in self.weights)\n",
                                        "        return float(ce)\n",
                                        "\n",
                                        "    def backward(self, y_one_hot: np.ndarray) -> None:\n",
                                        "        if not self._cache:\n",
                                        "            raise RuntimeError(\"Nothing to backpropagate. Call forward(store=True) before backward().\")\n",
                                        "\n",
                                        "        activations = self._cache[\"activations\"]\n",
                                        "        pre_activations = self._cache[\"pre_activations\"]\n",
                                        "        batch_size = y_one_hot.shape[0]\n",
                                        "\n",
                                        "        grads_w = [np.zeros_like(w) for w in self.weights]\n",
                                        "        grads_b = [np.zeros_like(b) for b in self.biases]\n",
                                        "\n",
                                        "        delta = activations[-1] - y_one_hot\n",
                                        "\n",
                                        "        for layer in reversed(range(len(self.weights))):\n",
                                        "            grads_w[layer] = (activations[layer].T @ delta) / batch_size + self.l2 * self.weights[layer]\n",
                                        "            grads_b[layer] = np.sum(delta, axis=0, keepdims=True) / batch_size\n",
                                        "\n",
                                        "            if layer != 0:\n",
                                        "                delta = (delta @ self.weights[layer].T) * relu_derivative(pre_activations[layer - 1])\n",
                                        "\n",
                                        "        self._grads = {\"weights\": grads_w, \"biases\": grads_b}\n",
                                        "\n",
                                        "    def _apply_gradients(self) -> None:\n",
                                        "        if not self._grads:\n",
                                        "            raise RuntimeError(\"Call backward() before applying gradients.\")\n",
                                        "\n",
                                        "        for idx in range(len(self.weights)):\n",
                                        "            self.weights[idx] -= self.learning_rate * self._grads[\"weights\"][idx]\n",
                                        "            self.biases[idx] -= self.learning_rate * self._grads[\"biases\"][idx]\n",
                                        "\n",
                                        "    def train_batch(self, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
                                        "        y_one_hot = one_hot(y, self.layer_sizes[-1])\n",
                                        "        probabilities = self.forward(X, store=True)\n",
                                        "        loss = self.compute_loss(y_one_hot, probabilities)\n",
                                        "        self.backward(y_one_hot)\n",
                                        "        self._apply_gradients()\n",
                                        "        predictions = np.argmax(probabilities, axis=1)\n",
                                        "        batch_accuracy = accuracy_score(y, predictions)\n",
                                        "        return loss, batch_accuracy\n",
                                        "\n",
                                        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
                                        "        return self.forward(X, store=False)\n",
                                        "\n",
                                        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
                                        "        probabilities = self.predict_proba(X)\n",
                                        "        return np.argmax(probabilities, axis=1)\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def iterate_minibatches(\n",
                                        "    X: np.ndarray,\n",
                                        "    y: np.ndarray,\n",
                                        "    batch_size: int,\n",
                                        "    shuffle: bool = True,\n",
                                        "    seed: int | None = None,\n",
                                        ") -> Iterable[Tuple[np.ndarray, np.ndarray]]:\n",
                                        "    indices = np.arange(X.shape[0])\n",
                                        "    if shuffle:\n",
                                        "        rng = np.random.default_rng(seed)\n",
                                        "        rng.shuffle(indices)\n",
                                        "\n",
                                        "    for start in range(0, len(indices), batch_size):\n",
                                        "        excerpt = indices[start : start + batch_size]\n",
                                        "        yield X[excerpt], y[excerpt]\n",
                                        "\n",
                                        "\n",
                                        "def evaluate(model: MLP, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
                                        "    probabilities = model.predict_proba(X)\n",
                                        "    y_one_hot = one_hot(y, model.layer_sizes[-1])\n",
                                        "    loss = model.compute_loss(y_one_hot, probabilities)\n",
                                        "    predictions = np.argmax(probabilities, axis=1)\n",
                                        "    acc = accuracy_score(y, predictions)\n",
                                        "    return loss, acc\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "learning_rate = 0.05\n",
                                        "hidden_layers = [16, 8]\n",
                                        "epochs = 200\n",
                                        "batch_size = 32\n",
                                        "l2_strength = 1e-4\n",
                                        "\n",
                                        "layer_sizes = [num_features, *hidden_layers, num_classes]\n",
                                        "model = MLP(layer_sizes, learning_rate=learning_rate, l2=l2_strength)\n",
                                        "\n",
                                        "history: dict[str, list[float]] = {\n",
                                        "    \"train_loss\": [],\n",
                                        "    \"train_acc\": [],\n",
                                        "    \"val_loss\": [],\n",
                                        "    \"val_acc\": [],\n",
                                        "}\n",
                                        "\n",
                                        "for epoch in range(epochs):\n",
                                        "    batch_losses = []\n",
                                        "    batch_accs = []\n",
                                        "\n",
                                        "    for X_batch, y_batch in iterate_minibatches(\n",
                                        "        X_train, y_train, batch_size=batch_size, shuffle=True, seed=epoch\n",
                                        "    ):\n",
                                        "        loss, acc = model.train_batch(X_batch, y_batch)\n",
                                        "        batch_losses.append(loss)\n",
                                        "        batch_accs.append(acc)\n",
                                        "\n",
                                        "    train_loss = float(np.mean(batch_losses))\n",
                                        "    train_acc = float(np.mean(batch_accs))\n",
                                        "    val_loss, val_acc = evaluate(model, X_test, y_test)\n",
                                        "\n",
                                        "    history[\"train_loss\"].append(train_loss)\n",
                                        "    history[\"train_acc\"].append(train_acc)\n",
                                        "    history[\"val_loss\"].append(val_loss)\n",
                                        "    history[\"val_acc\"].append(val_acc)\n",
                                        "\n",
                                        "    if (epoch + 1) % 20 == 0 or epoch == 0:\n",
                                        "        print(\n",
                                        "            f\"Epoch {epoch + 1:03d} | \"\n",
                                        "            f\"train loss {train_loss:.4f} | train acc {train_acc:.3f} | \"\n",
                                        "            f\"val loss {val_loss:.4f} | val acc {val_acc:.3f}\"\n",
                                        "        )\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "epochs_axis = np.arange(1, epochs + 1)\n",
                                        "\n",
                                        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                                        "\n",
                                        "axes[0].plot(epochs_axis, history[\"train_loss\"], label=\"train\")\n",
                                        "axes[0].plot(epochs_axis, history[\"val_loss\"], label=\"validation\")\n",
                                        "axes[0].set_title(\"Cross-Entropy Loss\")\n",
                                        "axes[0].set_xlabel(\"Epoch\")\n",
                                        "axes[0].set_ylabel(\"Loss\")\n",
                                        "axes[0].legend()\n",
                                        "\n",
                                        "axes[1].plot(epochs_axis, history[\"train_acc\"], label=\"train\")\n",
                                        "axes[1].plot(epochs_axis, history[\"val_acc\"], label=\"validation\")\n",
                                        "axes[1].set_title(\"Accuracy\")\n",
                                        "axes[1].set_xlabel(\"Epoch\")\n",
                                        "axes[1].set_ylabel(\"Accuracy\")\n",
                                        "axes[1].legend()\n",
                                        "\n",
                                        "plt.tight_layout()\n",
                                        "plt.show()\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def plot_decision_boundary(\n",
                                        "    model: MLP,\n",
                                        "    X: np.ndarray,\n",
                                        "    y: np.ndarray,\n",
                                        "    title: str = \"Decision Boundary\",\n",
                                        "    grid_step: float = 0.02,\n",
                                        ") -> None:\n",
                                        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
                                        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
                                        "    xx, yy = np.meshgrid(\n",
                                        "        np.arange(x_min, x_max, grid_step),\n",
                                        "        np.arange(y_min, y_max, grid_step),\n",
                                        "    )\n",
                                        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
                                        "    probabilities = model.predict_proba(grid)\n",
                                        "    predictions = np.argmax(probabilities, axis=1).reshape(xx.shape)\n",
                                        "\n",
                                        "    plt.figure(figsize=(6, 5))\n",
                                        "    plt.contourf(xx, yy, predictions, alpha=0.3, cmap=plt.cm.coolwarm)\n",
                                        "\n",
                                        "    for cls in np.unique(y):\n",
                                        "        plt.scatter(\n",
                                        "            X[y == cls, 0],\n",
                                        "            X[y == cls, 1],\n",
                                        "            label=f\"class {cls}\",\n",
                                        "            edgecolor=\"k\",\n",
                                        "            alpha=0.8,\n",
                                        "            s=40,\n",
                                        "        )\n",
                                        "\n",
                                        "    plt.xlabel(\"feature 1\")\n",
                                        "    plt.ylabel(\"feature 2\")\n",
                                        "    plt.title(title)\n",
                                        "    plt.legend()\n",
                                        "    plt.show()\n",
                                        "\n",
                                        "\n",
                                        "plot_decision_boundary(model, X_test, y_test, title=\"Decision Boundary on Test Data\")\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "sample_points = X_test[:5]\n",
                                        "predicted_labels = model.predict(sample_points)\n",
                                        "\n",
                                        "print(\"Predicted:\", predicted_labels)\n",
                                        "print(\"Ground truth:\", y_test[:5])\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "## Next steps\n",
                                        "\n",
                                        "- Experiment with different activation functions (e.g. sigmoid, tanh) or deeper architectures by modifying `hidden_layers`.\n",
                                        "- Try alternative optimisation strategies such as momentum or RMSProp to accelerate convergence.\n",
                                        "- Replace the mock dataset with your own data by saving it to `../data/mock_classification.csv` with the same schema.\n"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "Python 3",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.13.5"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 5
}
